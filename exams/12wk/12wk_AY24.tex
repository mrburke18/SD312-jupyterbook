\documentclass[letterpaper,noanswers,addpoints]{exam}
%\printanswers
\usepackage{listings}
\usepackage{color}
\usepackage{graphicx}
\usepackage{amsmath}
\DeclareMathOperator*{\argmin}{arg\,min}

\lstset{language=Java,
numbers=left,
tabsize=4,
breaklines,
basicstyle=\small\ttfamily,
keywordstyle=\bfseries,
stringstyle=\ttfamily,
showstringspaces=false}

\renewcommand{\solutiontitle}{\noindent\textbf{Solution: }}
\renewcommand{\thepartno}{\Alph{partno}}
\renewcommand{\thechoice}{\alph{choice}}
\CorrectChoiceEmphasis{\color{red}\bfseries}
\shadedsolutions

\pagestyle{headandfoot}
\runningheadrule
\firstpageheader{SD312}{12-Week Exam}{April 3, 2024}
\runningheader{SD312}{12-Week Exam}{April 3, 2024}
\runningfooter{}{Page \thepage\ of \numpages}{\makebox[0.25in]{\hrulefill} of
\pointsonpage{\thepage}}

\begin{document}
\makebox[4in]{Name:\enspace\hrulefill}
%\hspace{0.1in}
%\makebox[2in]{Section:\enspace\hrulefill}
\vspace{1in}

Write and sign the following: \emph{``The Naval Service I am a part of is bound by honor and integrity. I will not compromise our values by giving or receiving unauthorized help on this exam."}

\fbox{\parbox{6in}{\vspace{2in}\ }}

\vspace{.5in}
\makebox[3in]{Signature:\enspace\hrulefill}

\vfill

\begin{center}
  \gradetable[v][pages]
\end{center}
\vfill
\newpage

\begin{questions}
  \bracketedpoints
  \marginpointname{\ pts}
  \pointsinrightmargin

  \question[1] Name an activation function commonly used in neural nets.

  \fbox{\parbox{6in}{\vspace{.5in}\ }}

  %\question[3] In a single non-convolutional neuron with three inputs, which is part of a hidden layer, describe how an output is calculated.
  %
  %\fbox{\parbox{6in}{\vspace{2in}\ }}

  \vfill
  Given the below image of a neural net, which is designed to take in a vector of size 4 and output a vector of size 3, answer questions \ref{q:nnStart}-\ref{q:nnEnd}.

  \begin{figure}[h!]
    \centering
    \includegraphics[width=0.15\textwidth]{nn.pdf}
  \end{figure}

  \question[1] \label{q:nnStart} How many hidden layers are there?

  \fbox{\parbox{6in}{\vspace{.5in}\ }}

  \question[1] \label{q:nnEnd} How wide are those hidden layers?

  \fbox{\parbox{6in}{\vspace{.5in}\ }}

  \vfill
  \question[3] In a single neuron which is an output neuron in a regression problem, describe how an output is calculated.

  \fbox{\parbox{6in}{\vspace{2in}\ }}

  \vfill
  \question[1] Which of the following loss functions is appropriate for a regression problem?

  \begin{choices}
    \CorrectChoice Mean Squared Error
    \choice Cross Entropy Error
    \choice Triplet Margin Error
    \choice Reconstruction Error
  \end{choices}

  \newpage
  \question[1] Which of the following loss functions is appropriate for a classification problem?

  \begin{choices}
    \choice Mean Squared Error
    \CorrectChoice Cross Entropy Error
    \choice Triplet Margin Error
    \choice Reconstruction Error
  \end{choices}

  \question[3] Suppose a classification network outputs the logits [1.2, 0.03, and -2.1].  Calculate the equivalent probabilities.

  \fbox{\parbox{6in}{\vspace{2in}\ }}
  \begin{solution}
    exp() = [3.32, 1.03, .12]
    probs = [.74, .23, .03]
  \end{solution}

  \question[1] In the below image, the 3x3 box on the left represents a black and white image, and the 2x2 box on the right represents a kernel in a convolutional layer. Assuming a padding of 1 and stride of 1, what would the size of the output be?

  \begin{figure}[h!]
    \centering
    \includegraphics[width=0.25\textwidth]{kernel.pdf}
  \end{figure}

  \begin{choices}
    \choice 1x1
    \choice 2x2
    \choice 3x3
    \CorrectChoice 4x4
    \choice 5x5
  \end{choices}

  \question[3] Given the same image and kernel, with a padding of 0 and stride of 1, calculate the elements of the top row of the output.  Show your work for partial credit.

  \fbox{\parbox{6in}{\vspace{2in}\ }}
  \begin{solution}
    (.45*.12)+(.12*.35)+(.67*.67)+(.25*.23) = .6
    (.12*.12)+(.02*.35)+(.25*.67)+(.21*.23) = .237
  \end{solution}

  \question[2] Given the image below, draw the resulting output of applying a 2x2 MaxPool layer to the right of the image. Assume a stride of 2.

  \begin{figure}[h!]
    \includegraphics[width=0.25\textwidth]{for_CNN_pool.png}
  \end{figure}

  \vfill
  \question[1] What are the \emph{trainable/learnable} elements of a convolutional layer called?

  \fbox{\parbox{6in}{\vspace{.5in}\ }}

  \vfill
  \question[1] Give an example of a transformation that could be used to augment an image dataset.

  \fbox{\parbox{6in}{\vspace{2in}\ }}

  \newpage
  \question[3] Below is the Pytorch description of a convolutional neural net which has been trained on ImageNet to classify images into 1000 classes.  Assume you are going to use this network as an image classifier between five classes by using transfer learning.  Describe one way to alter this network to allow you to use it for this new task.  It may help to draw a horizontal line in the network description to denote where you are modifying the network.

  \begin{verbatim}
  GreatNet(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
      (1): ReLU(inplace=True)
      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
      (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
      (4): ReLU(inplace=True)
      (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
      (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (9): ReLU(inplace=True)
      (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (11): ReLU(inplace=True)
      (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
    (classifier): Sequential(
      (0): Linear(in_features=9216, out_features=4096, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): ReLU(inplace=True)
      (4): Linear(in_features=4096, out_features=1000, bias=True)
    )
  )
  \end{verbatim}

  \fbox{\parbox{6in}{\vspace{2in}\ }}

  \newpage
  \question[3] Describe at least two properties of a machine learning problem that would make transfer learning an appropriate solution for that problem.

  \fbox{\parbox{6in}{\vspace{1in}\ }}

  %\question[2] In transfer learning why are some layers \emph{frozen} during training?
  %
  %\fbox{\parbox{6in}{\vspace{2in}\ }}

  \vfill
  \question[1] Which of the following best describes the shape of an autoencoder which is intended for data points of 800 dimensions?

  \begin{choices}
    \CorrectChoice It takes in 800 dimensions, shrinks down to far fewer dimensions, then expands back to 800 dimensions.
    \choice It takes in 800 dimensions, and shrinks down to the number of classes in the dataset.
    \choice It takes in 800 dimensions, expands to far more dimensions, then shrinks back to 800 dimensions.
    \choice All of the above are valid shapes for autoencoders.
  \end{choices}

  \vfill
  \question[1] Which of the following is true about a well-trained autoencoder?

  \begin{choices}
    \choice The latent space is large dimensional and expressive.
    \CorrectChoice The output of the autoencoder is very similar to the input.
    \choice The output of the autoencoder is small and can be transferred quickly.
    \choice All datapoints exist far away from all other datapoints in the latent space.
  \end{choices}

  \vfill
  \question[3] In training an embedding network during contrastive learning, we use three datapoints, commonly referred to as $a$, $p$, and $n$.  Describe the relationship between those three points.

  \fbox{\parbox{6in}{\vspace{2in}\ }}

  \newpage
  \question[3] Assume we have an embedding network which creates 2-dimensional embeddings of datapoints, where $E(x)$ notates the embedding of the data point $x$.  For three datapoints $a$, $p$, and $n$, we have the following embeddings: $E(a)=[.1, .2]$, $E(p)=[.2, .3]$, and $E(n)=[.4, .2]$. Calculate the triplet margin loss of these three datapoints.  The margin is 1. Be sure to show your work for partial credit.

  \fbox{\parbox{6in}{\vspace{2in}\ }}
  \begin{solution}
    \begin{equation*}
      \| [.2,.3]-[.1,.2] \|_2 - \| [.1,.2]-[.4,.2] \| + 1\\
      \| [.1,.1] \| - \| [.3,0] \| +1\\
      .14-.3+1
      .84
    \end{equation*}
  \end{solution}

  %  \question[4] Give an example of a \textit{gallery} image and a \textit{probe} image that might be used in a facial recognition system. Defend what makes your examples appropriate for each usage.
  %
  %  \fbox{\parbox{6in}{\vspace{2in}\ }}

  \vfill
  \question[3] Suppose we have drivers license photographs for every resident of Maryland.  How would you use these to identify possible identities of a face captured in a security camera still?

  \fbox{\parbox{6in}{\vspace{2in}\ }}

  %\question[1] Give the image update equation for the fast gradient sign method adversarial attack.
  %
  %\fbox{\parbox{6in}{\vspace{2in}\ }}

  \vfill
  \question[3] Describe what an adversarial attack does. What is modified, and what is attacked?

  \fbox{\parbox{6in}{\vspace{2in}\ }}

  \newpage
  \question[3] Name one way (or give an example) in which the continued vulnerability of deep learning models to these attacks represents a danger to society or the military when employing them as solutions. 

  \fbox{\parbox{6in}{\vspace{2in}\ }}

  \question[3] Draw a picture to entertain your grader.

\end{questions}
\end{document}
