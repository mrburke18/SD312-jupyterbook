{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f70b1b-fb0b-4a22-b2ce-eb92d3a8257b",
   "metadata": {},
   "source": [
    "# Programming your own convolutional network\n",
    "\n",
    "Today's lab will use a common dataset called [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) to let us practice making a convolutional neural network for classification.  This dataset consists of 60,000 32x32 color pictures, each of which map to one of ten classes.  To do this, we'll use Pytorch's built-in CIFAR10 Dataset, so we won't need to program our own.\n",
    "\n",
    "The two cells below handle imports, and then build the training and testing Datasets.  The first time you run these, it will actually download the data for you.  Notice there are some transformations listed - you're welcome to add to these (and perhaps should), but you'll need at least these, which turn the image file into a Pytorch Image, and then convert them to 32-bit floats.\n",
    "\n",
    "The end of the second cell prints out the labels, just so we can see it's working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c305e97d-7e4a-46ff-ade2-312674d90da7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61c312e-6648-4812-895d-78d1f814ee49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "test_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "trainSet = CIFAR10('.', train=True, transform=train_transforms, download=True)\n",
    "testSet = CIFAR10('.', train=False, transform=test_transforms)\n",
    "actuallabels = trainSet.classes\n",
    "print('Labels are: ',actuallabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bef0f8-42fa-439f-8aee-fb96980f6634",
   "metadata": {},
   "source": [
    "OK!  Let's make sure that our Datasets are working.  Below I access the first element of the training set, which will give a tuple of the image and the first label (encoded as an integer, which is an index to the class list above).  I then display the first image - we should make sure the label and the image match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba7fab1-fdec-48d0-aa33-1519e462638a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "firstimg, firstlabel = trainSet[0]\n",
    "print(f'Label is index {firstlabel}, with semantic name {actuallabels[firstlabel]}')\n",
    "plt.imshow(firstimg.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3723017d-51a7-4f49-8a61-6a42730b9c55",
   "metadata": {},
   "source": [
    "Should look OK (though the image is displayed too large, perhaps).  Let's do the same thing with the first testing image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1820d45c-c4ca-4ca4-ac8c-617187e01850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "secimg, seclabel = testSet[0]\n",
    "print(f'Label is index {seclabel}, with semantic name {actuallabels[seclabel]}')\n",
    "plt.imshow(secimg.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a910ae-3229-4120-b7a0-5a6a47e72fb1",
   "metadata": {},
   "source": [
    "Now we build a DataLoader, which will handle pulling out batches for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af18877-36af-4baa-85f5-52905b4b87aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainLoader = DataLoader(trainSet, batch_size=100, shuffle=True, num_workers=4)\n",
    "testLoader = DataLoader(testSet, batch_size=100, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdf9ab0-1f3c-4bcd-bcbc-d623936629d7",
   "metadata": {},
   "source": [
    "You now should have everything you need to start performing your classification.  Build yourself a convolutional network, and train it to do as well as you can.  Create a function which measures accuracy.  Doing a reasonable job on CIFAR10 will give you a 90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b140e983-830b-4d46-a63c-e45db1d33a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ea16e54-7e3c-49e3-94c2-27b11f692481",
   "metadata": {},
   "source": [
    "To go further, consider doing the following things:\n",
    "\n",
    "- Add dataset augmentation, with more interesting transformations on your dataset.\n",
    "- Do a structured hyperparameter search.  For example, perhaps set up a loop of models to be trained, and at the end of each iteration of the loop, the model is saved to disk along with some notes on the train/test loss values and train/test accuracy values.  This will allow you to go back later and resurrect the one that did the best.\n",
    "- Scale up to CIFAR100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a690287-6faf-4b11-92ba-a296e3907cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
