{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e5fea0-b3d8-43dc-a561-fdd14d7360af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2945f9e-769f-404a-9ab2-ac027778b6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6878"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir='/home/scs/taylor/faculty/smallerSandbox'\n",
    "import os, glob\n",
    "jpg_files = glob.glob(os.path.join(dir, \"*.jpg\"))\n",
    "len(jpg_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a3c1c27-bc98-495d-a6f3-03c940721c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "\n",
    "class MidDataset(Dataset):\n",
    "    def __init__(self, dir, transform=None):\n",
    "        #super(MidDataset(), self).__init__()\n",
    "        self.dir = dir\n",
    "        self.filenames = glob.glob(os.path.join(dir, \"*.jpg\"))\n",
    "        self.N = len(self.filenames)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = read_image(self.filenames[idx])\n",
    "        if self.transform is not None:\n",
    "            return self.transform(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f609d88e-4206-4ccd-a22d-6430ccda7821",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms=v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32,scale=True)\n",
    "])\n",
    "test_transforms=v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32,scale=True)\n",
    "])\n",
    "\n",
    "\n",
    "data = MidDataset(dir, transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b4aed24-0b2a-4d17-9be3-30f504bc21b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=DataLoader(data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae0c10d-7013-419b-8cfc-18e47929b11f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
