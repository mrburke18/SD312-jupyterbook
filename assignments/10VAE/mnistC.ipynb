{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "492648cc-a52c-4f56-9e0e-381417bdd5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e7a46e1-5b2c-4e18-b833-36bbf9b13392",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "\n",
    "data = MNIST('./mnist_data', transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dbd6822-37c2-46ab-8f52-8947620342a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=data, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06c78b09-1171-4feb-9cee-b0339c67d864",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim=400, latent_dim=200):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2304, latent_dim)\n",
    "            )\n",
    "        \n",
    "        # latent mean and variance \n",
    "        self.mean_layer = nn.Linear(latent_dim, 2)\n",
    "        self.logvar_layer = nn.Linear(latent_dim, 2)\n",
    "        \n",
    "        # decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, latent_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(latent_dim, 2304),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Unflatten(1,(64,6,6)),\n",
    "            nn.ConvTranspose2d(64, 32, 3, 1, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(4608, 6272),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Unflatten(1,(32, 14, 14)),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose2d(32, 1, 3, 1, 1),\n",
    "            nn.Sigmoid(),\n",
    "            )\n",
    "     \n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mean, logvar = self.mean_layer(x), self.logvar_layer(x)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterization(self, mean, var):\n",
    "        epsilon = torch.randn_like(var).to('cuda')      \n",
    "        z = mean + var*epsilon\n",
    "        return z\n",
    "\n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterization(mean, logvar)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat, mean, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abea798a-5530-4c68-ac2a-46d7d6ca1a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nv=VAE().to('cuda')\\nx=data[2][0].reshape((1,1,28,28)).to('cuda')\\n#print(x.shape)\\nx1=v.encoder(x)\\nx1m=v.mean_layer(x1)\\nx1v=v.mean_layer(x1)\\nr=v.reparameterization(x1m,x1v)\\nv.decoder(r).shape\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "v=VAE().to('cuda')\n",
    "x=data[2][0].reshape((1,1,28,28)).to('cuda')\n",
    "#print(x.shape)\n",
    "x1=v.encoder(x)\n",
    "x1m=v.mean_layer(x1)\n",
    "x1v=v.mean_layer(x1)\n",
    "r=v.reparameterization(x1m,x1v)\n",
    "v.decoder(r).shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b0195c-abcd-49c6-a620-c27cf5dc7d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE().to('cuda')\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "827d696a-01b9-4c60-b80f-461546ec852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')\n",
    "    KLD = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return reproduction_loss + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e335f6ef-56a3-4e2a-ab85-4d3e66482253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch 1 \tAverage Loss:  206.4504948351419\n",
      "\tEpoch 2 \tAverage Loss:  206.45405923935726\n",
      "\tEpoch 3 \tAverage Loss:  206.44766593410893\n",
      "\tEpoch 4 \tAverage Loss:  206.4532203738001\n",
      "\tEpoch 5 \tAverage Loss:  206.4554186339211\n",
      "\tEpoch 6 \tAverage Loss:  206.4667662901711\n",
      "\tEpoch 7 \tAverage Loss:  206.44853473236645\n",
      "\tEpoch 8 \tAverage Loss:  206.45148108175084\n",
      "\tEpoch 9 \tAverage Loss:  206.44602850453882\n",
      "\tEpoch 10 \tAverage Loss:  206.46086801570326\n",
      "\tEpoch 11 \tAverage Loss:  206.44810067560516\n",
      "\tEpoch 12 \tAverage Loss:  206.44399686326167\n",
      "\tEpoch 13 \tAverage Loss:  206.44982793588272\n",
      "\tEpoch 14 \tAverage Loss:  206.44605690473705\n",
      "\tEpoch 15 \tAverage Loss:  206.44927724593072\n",
      "\tEpoch 16 \tAverage Loss:  206.44696391772746\n",
      "\tEpoch 17 \tAverage Loss:  206.45752797631468\n",
      "\tEpoch 18 \tAverage Loss:  206.44868517842238\n",
      "\tEpoch 19 \tAverage Loss:  206.44247326272955\n",
      "\tEpoch 20 \tAverage Loss:  206.4359237074812\n",
      "\tEpoch 21 \tAverage Loss:  206.4458152911102\n",
      "\tEpoch 22 \tAverage Loss:  206.45407684682806\n",
      "\tEpoch 23 \tAverage Loss:  206.44577688073872\n",
      "\tEpoch 24 \tAverage Loss:  206.45219020633348\n",
      "\tEpoch 25 \tAverage Loss:  206.4408716350167\n",
      "\tEpoch 26 \tAverage Loss:  206.43581799744365\n",
      "\tEpoch 27 \tAverage Loss:  206.45304964654633\n",
      "\tEpoch 28 \tAverage Loss:  206.44616431030886\n",
      "\tEpoch 29 \tAverage Loss:  206.4461823416632\n",
      "\tEpoch 30 \tAverage Loss:  206.4385776424249\n",
      "\tEpoch 31 \tAverage Loss:  206.44315450881678\n",
      "\tEpoch 32 \tAverage Loss:  206.43461452681552\n",
      "\tEpoch 33 \tAverage Loss:  206.4493846515025\n",
      "\tEpoch 34 \tAverage Loss:  206.44841206698663\n",
      "\tEpoch 35 \tAverage Loss:  206.44302170283805\n",
      "\tEpoch 36 \tAverage Loss:  206.43876640103298\n",
      "\tEpoch 37 \tAverage Loss:  206.44087470002086\n",
      "\tEpoch 38 \tAverage Loss:  206.4384285984453\n",
      "\tEpoch 39 \tAverage Loss:  206.43863786649624\n",
      "\tEpoch 40 \tAverage Loss:  206.432640533702\n",
      "\tEpoch 41 \tAverage Loss:  206.43023483149\n",
      "\tEpoch 42 \tAverage Loss:  206.45309242617904\n"
     ]
    }
   ],
   "source": [
    "def train(model, optimizer, epochs, x_dim=784):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        overall_loss = 0\n",
    "        for batch_idx, (x, _) in enumerate(loader):\n",
    "            x = x.to('cuda')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x_hat, mean, log_var = model(x)\n",
    "            loss = loss_function(x, x_hat, mean, log_var)\n",
    "            \n",
    "            overall_loss += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"\\tEpoch\", epoch + 1, \"\\tAverage Loss: \", overall_loss/(batch_idx*100))\n",
    "    return overall_loss\n",
    "\n",
    "train(model, optimizer, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d2fc23-7070-4b0b-9281-6841665de5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_sample = torch.tensor([[0, 0.0]],dtype=torch.float32).to('cuda')\n",
    "x_decoded = model.decode(z_sample)\n",
    "digit = x_decoded.detach().cpu().reshape(28,28)\n",
    "plt.imshow(digit, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d8dd00-b6f2-439a-a4dc-465069f121f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space(model, scale=1.0, n=25, digit_size=28, figsize=15):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "\n",
    "    # construct a grid \n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = torch.tensor([[xi, yi]], dtype=torch.float).to('cuda')\n",
    "            x_decoded = model.decode(z_sample)\n",
    "            digit = x_decoded[0].detach().cpu().reshape(digit_size, digit_size)\n",
    "            figure[i * digit_size : (i + 1) * digit_size, j * digit_size : (j + 1) * digit_size,] = digit\n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    plt.title('VAE Latent Space Visualization')\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"mean, z [0]\")\n",
    "    plt.ylabel(\"var, z [1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_latent_space(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7766df70-ebac-4f38-b81f-0888f0415ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
