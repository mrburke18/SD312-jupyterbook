import os
import argparse
parser=argparse.ArgumentParser()
parser.add_argument("gpu",type=int)
#other argparse stuff for your program
args=parser.parse_args()

gpu=args.gpu
assert gpu>=0 and gpu<4

os.environ["CUDA_VISIBLE_DEVICES"]=str(gpu)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
import tensorflow as tf
import numpy as np

'''
This block just builds random numpy arrays to stand in for your data.
D_in is the number of dimensions of a single datapoint
D_out is the number of dimensions in the target - since you're probably just
     predicting cases, a one-dimensional target, this will likely be 1.
N is the number of datapoints.

You will replace this with your data loading and processing. Don't forget
your feature normalization, which is not theoretically necessary on NNs,
but in practice makes them much more stable.
'''
D_in=7
D_out=2
N=50
X = np.random.rand(N,D_in)
y = np.random.rand(N,D_out)


'''
This builds the neural net.  In this case, it goes from a layer of D_in neurons
with ReLU activation functions, to a layer of 10 neurons with ReLU activation
functions, to a layer output D_out values, with no activation function (which
is appropriate for regression, since it doesn't limit the output).
'''
model=tf.keras.Sequential([
  tf.keras.layers.Dense(D_in,activation='relu'),
  tf.keras.layers.Dense(10,activation='relu'),
  tf.keras.layers.Dense(D_out)
  ])


model.compile(optimizer='adam', #Adam is a version of gradient descent with momentum
    loss=tf.keras.losses.MeanSquaredError(), #minimize MSE
    metrics=['MSE']) #display MSE

model.fit(X,y,
    validation_split=.25, #auto train/test splitting...
    callbacks=[tf.keras.callbacks.EarlyStopping(restore_best_weights=True)], #Stop when test error starts to increase
    epochs=100000)

#Once trained, models can be saved.
#At this point, model.predict() will make your predictions.
