{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a0829cc-d7a7-42ad-afed-7f627daf2341",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "Most image recognition tasks don't have enough data to adequately train a full-sized convolutional neural network.  As a result, it's common to instead do *transfer learning*.  In transfer learning, we first train a large neural net on a very large dataset we do have (or, more likely, we let someone else do it for us).  Presumably, those convolutional layers will then be able to extract useful features for all sorts of image tasks, not just the ones they were specifically trained for.\n",
    "\n",
    "We then take that large, trained neural net, chop off the fully-connected part at the end, replace it with a randomly-initialized new fully-connected part, and then train on our smaller dataset, only allowing those new layers to train.  Given the good features from the convolutional layers, we can hopefully build a good network for our specific task.\n",
    "\n",
    "You're going to build a neural net which performs classification between two types of things of your choice using transfer learning.  To do this, we're going to scrape Bing Images (yes! Bing!) for our dataset of images.\n",
    "\n",
    "## Step 0: Set up your environment\n",
    "\n",
    "This project has a couple extra requirements, so make a new virtual environment.\n",
    "\n",
    "- `mamba create -n transfer numpy scipy scikit-learn pandas plotly matplotlib jupyter pytorch torchvision opencv imutils tqdm torchinfo`\n",
    "- `mamba activate transfer`\n",
    "- `pip install standard-imghdr`\n",
    "- `mkdir imgs && cd imgs`\n",
    "- `pip install git+https://github.com/ostrolucky/Bulk-Bing-Image-downloader`\n",
    "- `cp ~/.local/bin/bbid* .`\n",
    "\n",
    "If that last command doesn't work, try `cp ~/miniforge3/envs/transfer/bin/bbid* .` instead.\n",
    "\n",
    "Then, in order to get around ITSD's nonsense, disable SSL verification by\n",
    "opening up `bbid.py`, and just below all the import statements, add:\n",
    "\n",
    "```python\n",
    "import ssl\n",
    "_create_unverified_https_context = ssl._create_unverified_context\n",
    "ssl._create_default_https_context = _create_unverified_https_context\n",
    "```\n",
    "\n",
    "## Step 1: Build a dataset\n",
    "\n",
    "You can download images of whatever you like to build your classifier.  Inside `~/imgs` is a file called `bbid.py`.  If you run `python bbid.py goats`, it will download a bunch of pictures of goats into `imgs/bing`.  You can then use [this script](mvr.sh) as `bash mvr.sh goats` to move most of them into `imgs/train/goats`, and the rest into `imgs/test/goats`.\n",
    "\n",
    "You'll want to do this for at least two types of things, of your choice, to build a classifier between.\n",
    "\n",
    "## Step 2: Train a neural net, based off the ResNet18 architecture\n",
    "\n",
    "Download this notebook. UNDERSTAND IT. Feel free to remove this explanatory cell, and then run it on your data.  It will probably work pretty well.  Then, look for things to modify.  Depth?  Width?  Dropout layers (google it!)? Activation functions?  More classes of images? Number of epochs?\n",
    "\n",
    "Here are some questions to explore:\n",
    "\n",
    "- How does adding more classes impact the performance of your learned model? Are some classes harder to differentiate from each other than others (use a confusion matrix)?\n",
    "- How does adding more layers impact the speed of convergence and the ultimate performance of the model?\n",
    "- Can you find some classes that you are unable to learn particularly well?\n",
    "- Does changing the learning rate have any effect?\n",
    "- If you remove the random transformations to the training set, or add others, how does test performance change?  Does it take longer to overfit?\n",
    "- If you don't train long enough, you'll underfit. If you train too long, you'll overfit. Can you implement early stopping (like many did for the movie recommendation project) so you stop at just the right time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6cdced-560d-4294-8a3e-7a4fe92408ad",
   "metadata": {},
   "source": [
    "## The code\n",
    "\n",
    "This code has a few extra bells and whistles, so read through to understand.\n",
    "\n",
    "First, imports and \"let's do insecure things to access the internet, because ITSD has a MITM attack.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a1286-d888-4216-a55f-6ba6feb2c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms\n",
    "import torchinfo\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import ssl\n",
    "_create_unverified_https_context = ssl._create_unverified_context\n",
    "ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47a0912-639d-4d89-b34e-75d65092895f",
   "metadata": {},
   "source": [
    "Our datasets will be built by pointing at the directories that contain the training and testing data. The different classes must be split within these folders. For example, `imgs/train` and `imgs/test` might have two folders each, called `goats` and `mules`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df57dd6-aeb8-44ef-aef3-5096b63dd694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#locations of training and testing data\n",
    "train_data_path='imgs/train'\n",
    "test_data_path='imgs/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a0475a-25ac-4f36-a4fc-c7da961da645",
   "metadata": {},
   "source": [
    "To reduce overfitting, it's common to randomly transform each training image so that it never shows up in quite the same way twice. We do not want to do that for our testing images, but we do need to resize them to the expected size and convert them to Tensors.\n",
    "\n",
    "We build our `Dataset` and `DataLoader` objects to read from the folders and apply the given transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2ca504-b7d7-4266-88b4-b1b198a4a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformations for training data\n",
    "random_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(256),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "#transformations for testing data\n",
    "common_transform=transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "#build datasets and dataloaders\n",
    "train_dataset=datasets.ImageFolder(root=train_data_path,transform=random_transform)\n",
    "test_dataset=datasets.ImageFolder(root=test_data_path,transform=common_transform)\n",
    "batch_size=32\n",
    "train_loader=DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader=DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a33bad-04a7-4e97-9611-5006e62b4094",
   "metadata": {},
   "source": [
    "We'll use ResNet18, which is a relatively small image classification network with about 11 million parameters. Have a look at the construction of the network, paying attention to both the feature extraction portion, and the final layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a686e462-755a-439f-bda9-50f88409dd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the model and its weights\n",
    "model=torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
    "#print out the summary of it. What's its final output size? Why?\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8269e688-5060-428e-ac68-1cbe8a215344",
   "metadata": {},
   "source": [
    "To do transfer learning, we tell the network not to train the feature extractor. We set `.requires_grad` for all these given parameters to `False` so they don't train.\n",
    "\n",
    "We then overwrite `model.fc` with one of our own. This will have random parameters, and will need to have the output format for our task.\n",
    "\n",
    "In addition, we push the model and its parameters to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c47d3ce-827c-4938-be5c-902a4c3fda1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the model parameters to be non-changeable\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "\n",
    "#Change model.fc to a single 512->2 layer - this could instead be a Sequential with multiple layers\n",
    "#This layer's trainable\n",
    "model.fc=torch.nn.Linear(in_features=512,out_features=2,bias=True)\n",
    "model=model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cfa172-50c9-4fb0-b8e4-9da18b9c0053",
   "metadata": {},
   "source": [
    "We train the network using CrossEntropyLoss, because we're doing classification. Note that as we read in each batch, we push the data and targets to the GPU in order to train there.\n",
    "\n",
    "There's a lot you could change here, including adding in Tensorboard or checking on testing error while it trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74232dcd-3e0a-4748-a328-d60897788df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=.001)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        data, target = data.to('cuda'), target.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx%100==0:\n",
    "            print(f\"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item()}\")\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to('cuda'), target.to('cuda')\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb5ce46-ef20-44cb-a716-9515ca8b764a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
